{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "import PoseTrackingModule as ptm\n",
    "import os\n",
    "\n",
    "from yoloV3 import YOLOdetector\n",
    "\n",
    "from DepthDetector import DepthDetector\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_name=\"Recordings/mixes_copy/\"\n",
    "\n",
    "Spark_filename= main_folder_name+\"Spark_image/\"\n",
    "Spark_numpys=main_folder_name+\"Spark_npys/\"\n",
    "Spark_mins=main_folder_name+\"Spark_mins/\"\n",
    "Spark_maxs=main_folder_name+\"Spark_maxs/\"\n",
    "\n",
    "Color_filename= main_folder_name+\"Color_RealSense/\"\n",
    "Depth_filename= main_folder_name+\"Depth_RealSense/\"\n",
    "Depthnp_filename = main_folder_name+\"Depthnp_RealSense/\"\n",
    "\n",
    "file_ext = \".jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Color_RealSense= []\n",
    "Depth_RealSense= []\n",
    "Depthnp_RealSense= []\n",
    "Spark_image= []\n",
    "Spark_maxS= []\n",
    "Spark_minS= []\n",
    "Spark_npys= []\n",
    "\n",
    "\n",
    "for file in os.listdir(Color_filename):\n",
    "    Color_RealSense.append(cv2.imread(Color_filename+file))\n",
    "\n",
    "for file in os.listdir(Depth_filename):\n",
    "    Depth_RealSense.append(cv2.imread(Depth_filename+file))\n",
    "\n",
    "for file in os.listdir(Depthnp_filename):\n",
    "    Depthnp_RealSense.append(np.load(Depthnp_filename+file))\n",
    "\n",
    "for file in os.listdir(Spark_filename):\n",
    "    Spark_image.append(cv2.imread(Spark_filename+file))\n",
    "\n",
    "for file in os.listdir(Spark_maxs):\n",
    "    Spark_maxS.append(np.load(Spark_maxs+file))\n",
    "\n",
    "for file in os.listdir(Spark_mins):\n",
    "    Spark_minS.append(np.load(Spark_mins+file))\n",
    "\n",
    "for file in os.listdir(Spark_numpys):\n",
    "    Spark_npys.append(np.load(Spark_numpys+file))\n",
    "\n",
    "\n",
    "depth_scale=np.load(main_folder_name+'depth_scale.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ptm.poseDetector()\n",
    "depthDetector=DepthDetector(depth_scale=depth_scale)\n",
    "yolo= YOLOdetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488219\n",
      "FACE flat_factor 332.65855742774545\n",
      "ThermalConfidence 1\n",
      "DepthConfidence 3\n",
      "125474\n",
      "FACE flat_factor 1116.307261320587\n",
      "ThermalConfidence 1\n",
      "DepthConfidence 3\n",
      "4028814\n",
      "FACE flat_factor 198230.7853533433\n",
      "ThermalConfidence 1\n",
      "DepthConfidence 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "136761\n",
      "FACE flat_factor 28342.119867440808\n",
      "ThermalConfidence 1\n",
      "DepthConfidence 3\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Color_RealSense)):\n",
    "    grideye_image = Spark_image[i]\n",
    "    color_image  = Color_RealSense[i]\n",
    "    depth_colormap = Depth_RealSense[i]\n",
    "    grideye_values=Spark_npys[i]\n",
    "    minTemp=Spark_minS[i]\n",
    "    maxTemp=Spark_maxS[i]\n",
    "    depth_map=Depthnp_RealSense[i]\n",
    "    yoloDetects = yolo.predict(color_image)\n",
    "    landmarks=[]\n",
    "    for yoloDetect in yoloDetects:\n",
    "        detectPoseRGB, detectPoseDepth, landmark = detector.findPoseAndDrawLandmarks(\n",
    "        color_image[yoloDetect[1]:yoloDetect[3],yoloDetect[0]:yoloDetect[2]], depth_map[yoloDetect[1]:yoloDetect[3],yoloDetect[0]:yoloDetect[2]])\n",
    "        landmarks.append(landmark)\n",
    "    \n",
    "    for l in landmarks:\n",
    "        if(l):\n",
    "            depth_map=depthDetector.detect(l,depth_map,grideye_values,minTemp,maxTemp)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Color RealSense image\", color_image)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    #cv2.imshow(\"Depth RealSense image\", detectPoseDepth)\n",
    "    #cv2.imshow(\"Dete RealSense image\", detectPoseRGB)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27 or i==len(Color_RealSense)-1:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##mediapipe only\n",
    "for i in range(len(Color_RealSense)):\n",
    "    grideye_image = Spark_image[i]\n",
    "    color_image  = Color_RealSense[i]\n",
    "    depth_colormap = Depth_RealSense[i]\n",
    "    grideye_values=Spark_npys[i]\n",
    "    minTemp=Spark_minS[i]\n",
    "    maxTemp=Spark_maxS[i]\n",
    "    depth_map=Depthnp_RealSense[i]\n",
    "\n",
    "\n",
    "\n",
    "    detectPoseRGB, detectPoseDepth, landmarks = detector.findPoseAndDrawLandmarks(\n",
    "    color_image, depth_map)\n",
    "\n",
    "    \n",
    "    if(landmarks):\n",
    "        depth_map=depthDetector.detect(landmarks,depth_map,grideye_values,minTemp,maxTemp)\n",
    "    \n",
    "    \n",
    "    # cv2.imshow(\"Color RealSense image\", color_image)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    #cv2.imshow(\"Depth RealSense image\", detectPoseDepth)\n",
    "    #cv2.imshow(\"Dete RealSense image\", detectPoseRGB)\n",
    "    k = 0#cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points=[]\n",
    "\n",
    "depths=[]\n",
    "#get the depths inside the four points inside which the object is\n",
    "for i in range(int(landmarks[24][0]),int(landmarks[23][0])):\n",
    "    for j in range (int(landmarks[12][1]),int(landmarks[24][1])):\n",
    "            depths.append([float(depth_map[j][i].astype(float)*self.depth_scale*1000)])#distance in cm\n",
    "depths = np.array(depths)\n",
    "points = np.array(points)\n",
    "# Fit a plane to the points using the RANSAC algorithm\n",
    "ransac = RANSACRegressor(min_samples=3)\n",
    "model = ransac.fit(points, depths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "005db13d4d21fd76fe15f2a0136d58b4adeae6da8ba7bcb24a0e6f1aa90176c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
